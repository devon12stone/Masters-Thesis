\chapter{Data Extraction and Preprocessing} 
\label{Chapter3}

This chapter details the data sources used to train the various loan default prediction models developed throughout this project, the various data extraction techniques used to extract the alternative features within the training sets, and the pre-processing and feature engineering techniques deployed before the modelling phase.   
%---------------------------------------------------------------------------------------
%	SECTION 1
%---------------------------------------------------------------------------------------

\section{Data Used}

\subsection{Providers}

There were two main sources that provider the data used to train the models developed throughout this project. \\

The first data provider is a Nigerian micro-finance institution that has disbursed loans to more than 250,000 consumers. The institution is an application-based lender and currently only provides credit to android users. The institution, with its customers' consent, gains access to the data on customers' devices. This data includes SMS data, contact data and location data. On top of the alternative data collected, sociodemographic data is collected via customer input on the institution's application. \\

The second source of data for this project was the Nigerian credit bureaus CRC, CRS and XDS. It is mandatory for credit providing institutions in Nigeria to submit their customers' credit performance data to these credit bureaus.

\subsection{Personal Data}

It is key to note that no personal data, data that relates to an identified or could be used to identify a living individual, was not made publicly available, used within the creation of features, or used to train the models developed throughout this project. 

\subsection{Dataset}

A final dataset was created for first time loan customers of the micro-finance institution that had existing credit bureau data prior to their first application. The customers required existing credit data as it was needed in order to compare the performance of first time credit credit scoring models that use only alternative data or alternative data in conjunction with sociodemographic data, against first time credit scoring models that make use of existing credit data. The final dataset consisted of 49,550 customers/loans. 

\subsection{Data Categories}

Three major data categories were drawn from the data sources. These categories were sociodemographic data, credit bureau data and alternative data. The main aim of this thesis is to assess how alternative data can augment traditional credit scoring data. To complete this aim various combinations of these data categories were used to develop various credit scoring models. The statistical performance of the models were assessed in order to test whether using the various data categories resulted in a significant difference in model performance. 

\subsection{Variables Used}

Table \ref{table:variables} in the appendix attached to this report, displays all variables used to develop the loan default prediction models built. All sociodemographic variables used were stated by the loan applicants. The application, device ,and SMS related variables were scraped from applicant's device. While, the credit bureau related variables were provided by the Nigerian credit bureaus.  \\




%---------------------------------------------------------------------------------------
%	SECTION 2
%---------------------------------------------------------------------------------------

\section{Data Extraction and Feature Engineering}

\subsection{Sociodemographic and Credit Bureau Data}

The more traditional credit scoring features, developed from sociodemographic and credit bureau data attached to each first-time borrower, were created and extracted using SQL (Structured Query Language). The data was extracted from the company's relational database. \\

The query was written in a manner that ensured that no data leakage would occur when the credit scoring models were being trained. This means that only data that would be known at the point in time when a particular client applied for their loan could be sued to develop features. The only case were data was used that would not be known at the point in time of application was repayment data, as this was used to develop the default (whether the client repaid their loan or not) target variable. \\

The overall query used to extract the sociodemographic and credit bureau for each loan was a collection of sub-queries joined on a unique key attached to each loan. The query used to extract the credit bureau required an aggregation in order to generate features that represented the total number of loans each client had prior to their application with the micro-finance institution used in this study. The credit bureau features used in the modelling process and their definitions can be found in the appendix of this paper. The sociodemographic data was extracted using a simpler sub-query,  like the credit bureau features their definitions can be found in the appendix of this paper.  \\


\subsection{Alternative Data}

The three main sources of alternative data used to develop features were the application, SMS, and device data stored on each customers' cellphone. The data was extracted from the micro-finance institution's using PyMongo, a Python package that allows a user to query data from a Mongo database from within a Python script. The application and SMS data was extracted from different Mongo databases, however expressions (regex) were used to filter both data types and to develop features. Regex functions are sets of sequences of characters that define a particularly search pattern. The functions are then used to identify cases of the defined pattern in strings \parencite{Regex}. \\

The device data was extracted from a separate database as the application and SMS data and an entirely different technique was used to generate features from the data. The technique used in this case was web scraping, which is a method of extracting data from websites \parencite{WebScraping}. 

\subsubsection{Application Based Features}

The application based features engineered for this project were counts of particular applications present on a clients device at the point in time of their application. The features included a count of the finical, competing micro-finance, news, gambling and virtual private network (VPN) applications. The counts were generated by first compiling a list of all unique applications on a client's. Then the name of each application was passed through a series of regular expression key word searches. Each expression was designed to detect a specific application type. If  a particular application type search resulted in a match, the count associated with that search was updated. \\

The process developed to pass an application through the application extracting regular expressions and how the count features were generated throughout this process is represented in Figure \ref{fig:app_features}. The process was coming up completed for every unique application recorded on the client's device. 


\vspace{10 pt}

\begin{figure}[!htb]
\centering
\includegraphics[width=0.55\textwidth]{images/app_feats.png}
\caption{Application Based Feature Generation}
\label{fig:app_features}
\end{figure}


\subsubsection{SMS Based Features}

The SMS data consisted of messages received by the clients in the 90 days prior to their application, by nature this data is more sensitive than the other data used throughout this research. Similarly to the process developed to generate the application based features, each message received by a client was complied into a list. The list was the looped over in order to generate features for each client. \\

In order to avoid exposing personal messages the each message was passed through two filtering regular expressions. The first expression returned only messages received from Nigerian banks, while the second ensured that only messages returned by competitor micro-finance institutions were returned. The regular expressions had a dual purpose. They prevented exposure to sensitive content and they acted as the first step in the SMS based feature generation process. \\

If a message passed through the regular expression for banking messages it was exposed to the banking feature creation process. Typically, messages from Nigerian banks have a similar structure. They display a transaction amount, the date of the transaction, the type of transaction (credit or debit to the account), and finally the balance in the account after the transaction. Regular expressions were used these features and store them as either numeric variables or lists.  \\

If a message did not pass through the banking regular expression it was then passed to the competitor expression. If the message passed through this expression it was then further screened by another set of regex functions. These functions searched for key words in order to identify if a client had another loan with a competitor and if that loan had been repaid successfully or not. The actual loan amount was extracted using regex as was the loan repayment (instalment amount). These amounts were appended to lists. \\

After the passing every message associated to a particular client through the regex functions the lists created throughout the process were used to generate the SMS based features for that particular client. \\

\vspace{10pt}

The banking related features generated were:

\begin{itemize}
    \item The number of unique banks that sent the client a message
    \item The minimum and maximum debit transaction, credit transaction and account balance values extracted
    \item The total number of debit and credit transactions recorded
    \item The number of times the term 'insufficient funds' was recorded in the client's messages
\end{itemize}

\vspace{10pt}

The process of passing an SMS through the bank related regular expressions and how the banking features were generated throughout that process is represented in Figure \ref{fig:bank_features}. The process was completed for every message received by a client within the 90 day period prior to their application. 

\vspace{10pt}

\begin{figure}[!htb]
\centering
\includegraphics[width=0.95\textwidth]{images/bank_feats.png}
\caption{Bank Based Feature Generation}
\label{fig:bank_features}
\end{figure}

\vspace{10pt}

\newpage

The competitor related features generated were:

\begin{itemize}
    \item The number of competitors that sent the client a message
    \item The number of competitors that sent a loan to the client
    \item The minimum and maximum loan amount received by, successful loan repayment made by, and unsuccessful loan repayment made by the client
    \item The number of loans received by, successful loan repayments made by, and unsuccessful loan repayments made by the client
    \item The number of rejected loan applications made by the client. 
\end{itemize}

\vspace{10pt}

The process of passing an SMS through the competitor related regular expressions and how features were generated throughout that process is represented in Figure \ref{fig:comp_features}. The process was completed for every SMS message received by a client within the 90 day period prior to their application. 

\vspace{10pt}

\begin{figure}[!htb]
\centering
\includegraphics[width=0.95\textwidth]{images/comp_feats.png}
\caption{Competitor Based Feature Generation}
\label{fig:comp_features}
\end{figure}

\vspace{10pt}


\subsubsection{Web Scraping}

The unique Android ID attached to each customer's cellular device, used to apply for their loan, was used to ascertain the brand and model of the device as well as the operating version currently used on the device. The brand of device and operating system system were used directly as features while the device brand name and model were used in conjunction to scrape the price of the device. \\

The script written to scrape and calculate the device price was written in Python and made use of the Beautiful Soup web scraping package. The price of each device was scraped from Jumia and Kara, two of the biggest Nigerian e-commerce platforms. \\

The price was scraped from both websites by passing the name and model of the device into the respective search URL of each website. The Jumia search URL appears as follows \url{https://www.jumia.com.ng/phones-tablets/?q={NameAndBrand}&sort=Price}. The price was then scraped from the first page returned by the search. The prices were contained within specific HTML (hypertext markup language) tags on each website. This made the scraping simple. \\

The logic used to derive a price for each customer's cellular device is shown in Figure \ref{fig:device}.

\vspace{10pt}

\begin{figure}[!htb]
\centering
\includegraphics[width=0.95\textwidth]{images/device_price.png}
\caption{Device Price Logic}
\label{fig:device}
\end{figure}

\vspace{10pt}


Figure \ref{fig:device} displays the possible ways in which a device price could be determined. The possibilities are as follows: a price could not be scraped from either site, therefore, the price was set to null; a price could be scraped from one site but not the other, the scraped price was within the price bounds, then the one price was used; a price could be scraped from both sites, both prices were within the price bounds, then the price was set to be the mean of both prices. \\

Lower and upper price bounds were introduced to reduce the number of scraping miss-classifications and as a result improve data integrity. Unreasonably low prices were often device accessories such as phone cases or screen protectors. While unreasonably high prices were often laptops or other more expensive electronic devices. \newpage

%---------------------------------------------------------------------------------------
%	SECTION 3
%---------------------------------------------------------------------------------------

\section{Preprocessing}

\subsection{Scaling and Encoding}

Often in machine learning projects numeric scaling and categorical encoding is completed after missing value imputation. In the case of this project a K-Nearest Neighbours (KNN) model was developed to impute the missing values. The KNN algorithm involves calculating the distance between each data point in the dataset in consideration and every other point in that set. If features are not scaled prior to calculating the distances between points certain features may skew the calculated distances \parencite{KNNScaling}. Therefore, numeric variables were normalised and categorical variables scaled prior to missing value imputation. 

\subsubsection{Numeric Variables}

The numeric variables used throughout this project were normalised before the modelling process. Normalising numeric features involves transforming the values of each variable so that the values of variable follow a normal distribution where the mean is 0 and the standard deviation is 1. This is done for a single variable by first calculating the mean and standard deviation of the variable and then replacing the each value by its respective z-score \parencite{ZScore}. \\

The Z-score of each value is show in Equation \ref{eqn:z}, where x each value. 

\vspace{10pt}

\begin{equation}\label{eqn:z}
    z_{i} = \dfrac{x_{i}-\mu}{\sigma}
\end{equation}

\vspace{10pt}

The above transformation was done for every populated value of each variable in the dataset. It is key to note that missing values remained missing.  

\subsubsection{Categorical Variables}

The categorical variables contained in the dataset of this project were encoded using weight of evidence (WoE) encoding. This is a common approach for handling categorical variables within the credit risk and financial industries. WoE encoding scales the levels of a categorical predictor variables based on their relationship with the target variable, where the levels of a categorical variable are the possible outcomes of the variable. In terms of loan default prediction on models, WoE scales the levels of each categorical variable with respect to loan default \parencite{WOE}. \\

Another attribute of WoE encoding is that it handles missing values for categorical variables. In the case of the loan default prediction models missing values are consider to be missing not at random, this is because applicants may purposefully wit-hold information on their loan applications in order to increase their chance of having their application being accepted. This is further explain in sub-section 3.3.2. WoE encoding places missing values into a category and assigns a scaled value to them. \\

The method for calculating the WoE of each level is shown in Equation \ref{eqn:woe}, where probability of repaid (POR) and probability of defaulted (POD) are the number of customer that repaid in that level the total number of customers within that variable  and the number of customers that defaulted in that level the total number of customers within the variable respectively. 

\vspace{10pt}

\begin{equation}\label{eqn:woe}
    WoE = \ln{(\dfrac{POR}{POD})}
\end{equation}

\vspace{10pt}

An example of the WoE scores for one of the features used in this project can be seen in Table \ref{table:woe}. It is key to note that all WoE scores where then scaled using the normalisation method explained in Equation \ref{eqn:z} before being used in the KNN imputation model.  

\vspace{10pt}

\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|} 
\hline
\multicolumn{1}{|c}{Level} &\multicolumn{1}{|c|}{WoE}\\
\hline
Single & -13.16  \\
\hline
Married & 16.15  \\
\hline
Widowed & 6.54  \\
\hline
Separated & 13.82\\
\hline
Missing & 93.80\\
\hline
\end{tabular}
\end{center}
\caption{Weight of Evidence Values for Marital Status Variable}
\label{table:woe}
\end{table}


\vspace{10pt}

\subsection{Missing Values}

Missing values are an issue that need to be addressed during any data science project, however missing data is especially significant in credit risk related modelling. Gathering complete credit repayment data is the most important factor when developing credit risk models \parencite{MissingValuesBos}.

\subsubsection{Target Variable}

Repayment data is often sparse and complex. Many consumers have missing values based on incompleteness but others have missing values based on the fact that credit term has not been reached. These challenges make it difficult to develop statistically significant datasets required for credit repayment prediction models \parencite{MissingValuesCR}. \\ 

The loan repayment data used in this minor dissertation was complete. Only loanees that had completed their entire loan tenor and that all all their instalments for that particular loan were used in the dataset. This ensured that the target variable, loan default, did not contain any missing values. 49,550 first time applicants with a complete loan cycle were collected, which was enough to develop statistically significant training and testing samples. 

\subsubsection{Predictor Variables}

The features used to predict repayment did contain missing values. The missing values needed to either be removed or imputed. Firstly, the percent of missing values per predictor variable was assessed to ensure that no more than 50 percent of the values within each variable were missing. This was also done for each row. No more than 50 percent of the values contained in a variable or in a particular row were missing. \newpage

Figure \ref{fig:nullity} displays a nullity correlation heat-map of the variables within the dataset used throughout this project. A nullity correlation between two variables ranges from -1 to 1. A value of -1 indicates that if the one variable appears then the other will definitely not appear. A value of 0 indicates that the  appearance of the one variable does not influence the appearance of the other variable. A value of 1 indicates that the appearance of the one variable will lead to the definite appearance of the other \parencite{nullity}.  \\

\vspace{10pt}

\begin{figure}[!htb]
\centering
\includegraphics[width=0.95\textwidth]{images/nutility_correlation.png}
\caption{Nullity Correlation}
\label{fig:nullity}
\end{figure}

\vspace{10pt}

It can be seen if Figure \ref{fig:nullity} that no particular feature disparages the presence of another. However, the presence of certain features strongly correlates with the presence of other features. This is expected as no feature is sparsely populated. \\

 In other data science projects, rows containing missing values are often removed from the dataset \parencite{MissingValues}.  In the case of this project excluding all cases containing a missing value was not feasible as too few samples would have remained to train and test a valid model. This is because more than 50 percent of rows within the dataset contained at least one missing value. \\

Another common missing value imputation technique involves replacing missing values with the mean (continuous variables) or mode (categorical variables) of their respective variable. This is a successful technique if the variables are considered to be missing at random. In the case of this project missing values were consider to be missing not at random. This is due to the fact that the loanees manually filled certain variables during their loan applications. Loanees may have withheld or altered variables based on how they thought it would affect the outcome of their credit application \parencite{MissingValuesBos}. \\

There are many methods for imputing missing values where the values are missing not at random. The two methods explored were SVD (single value decomposition) and k-nearest neighbours. \\

SVD involves calculating a matrix's mutually orthogonal eigenvectors. The most important eigenvectors are then linearly combined in order to best predict the missing values of the matrix. In the case of the dataset used in this project, each loan application would be considered as a matrix row and the predictor variables would be the respective columns. An issue with SVD imputation is that the predictions for missing values are calculated using the most important eigenvectors and not all eigenvectors. Therefore, in terms of this project, unusual loan cases would not be would not be not well represented by the leading eigenvectors and as a result their missing values may not be accurately filled. This lead to the KNN approach being used \parencite{MissingValuesStandford}. \\

The KNN approach involves filling the missing values of a particular row with the aggregated value of the equivalent variable from the rows 'K' most similar neighbours. Similarity can be calculated using a various distance metric, for example Euclidean, Minkowski, and Manhattan distances. Equation \ref{eq:eucidean} shows the Euclidean distance between points x and y. The distances is calculated by take the square root of the sum of the squared differences between the respective variables of each point \parencite{EuclideanDist}. 

\vspace{10pt}

\begin{equation} \label{eq:eucidean}
d(x,y)=\sqrt{(x_{1}-y_{1})^{2} + (x_{2}-y_{2})^{2} + ... + (x_{n}-y_{n})^{2}}
\end{equation}

\vspace{10pt}

Before the KNN model was developed to replace the missing in the dataset, each variable was normalised and scaled. This was done for both categorical and numeric variables. The methods used to do this are explained in sub-section 3.3.1.\\

After normalisation and scaling, the follow steps were completed in order to fill missing values for each loan in the dataset using the KNN approach: 

\begin{enumerate}
    \item Set the number of nearest neighbours to be considered for each loan to 3. 
    \item Check if the loan had any missing values. If the loan did not have missing values move to the next loan, if it did then continue to the steps below. 
    \item Calculate the Euclidean distance between the loan under consideration and every other loan. 
    \item Identify the 3 closest loan applications based upon Euclidean distance. 
    \item Fill each missing value with the mean value of the respective variable taken from the loan's 3 nearest neighbours. 
\end{enumerate}
